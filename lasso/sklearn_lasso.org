#+title: lasso example
#+startup: inlineimages

* source
http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py

* code
** preamble
#+begin_src ipython :session :exports both :results output
%matplotlib inline

import numpy as np
import matplotlib.pyplot as plt

from sklearn import cross_validation, datasets, linear_model
#+end_src

#+RESULTS:

** construct data
#+begin_src ipython :session :exports both :results output code
diabetes = datasets.load_diabetes()
X = diabetes.data[:150]
y = diabetes.target[:150]
#+end_src

#+RESULTS:

describe data
#+begin_src ipython :session :exports both :results output code
print(type(diabetes))
print(type(diabetes.data), diabetes.data.shape)
print(type(diabetes.target), diabetes.data.shape)
#+end_src

#+RESULTS:
: <class 'sklearn.datasets.base.Bunch'>
: <class 'numpy.ndarray'> (442, 10)
: <class 'numpy.ndarray'> (442, 10)

#+begin_src ipython :session :exports both :results output code
print("X:\n", X)
print("X shape:\n", X.shape)
print("y:\n", X)
#+end_src

#+RESULTS:
#+begin_example
X:
 [[ 0.03807591  0.05068012  0.06169621 ..., -0.00259226  0.01990842
  -0.01764613]
 [-0.00188202 -0.04464164 -0.05147406 ..., -0.03949338 -0.06832974
  -0.09220405]
 [ 0.08529891  0.05068012  0.04445121 ..., -0.00259226  0.00286377
  -0.02593034]
 ...,
 [-0.05637009 -0.04464164  0.09295276 ...,  0.02545259  0.02605609
   0.04034337]
 [-0.06000263  0.05068012  0.01535029 ..., -0.00259226 -0.03075121
  -0.0010777 ]
 [-0.04910502  0.05068012 -0.00512814 ...,  0.07120998  0.06123791
  -0.03835666]]
X shape:
 (150, 10)
y:
 [[ 0.03807591  0.05068012  0.06169621 ..., -0.00259226  0.01990842
  -0.01764613]
 [-0.00188202 -0.04464164 -0.05147406 ..., -0.03949338 -0.06832974
  -0.09220405]
 [ 0.08529891  0.05068012  0.04445121 ..., -0.00259226  0.00286377
  -0.02593034]
 ...,
 [-0.05637009 -0.04464164  0.09295276 ...,  0.02545259  0.02605609
   0.04034337]
 [-0.06000263  0.05068012  0.01535029 ..., -0.00259226 -0.03075121
  -0.0010777 ]
 [-0.04910502  0.05068012 -0.00512814 ...,  0.07120998  0.06123791
  -0.03835666]]
#+end_example


** Lasso estimator
Lasso:
\[
  \min_w \frac{1}{2 n_{samples}} {|| X w - y ||}_2^2 + \alpha {|| w ||}_1
\]

\(\alpha\) is provided by user.
When \(alpha\) (defaults to 1.0) equals 0, the linear model is an OLS.
\(alpha\) is different from the ~l1_ratio~.

Test lasso, with/out normalization of X
#+begin_src ipython :session :exports both :results output code
test_alpha = 0.2
clf = linear_model.Lasso(alpha=test_alpha, normalize=False)
clf1 = linear_model.Lasso(alpha=test_alpha, normalize=True)

print("fit clf with X and y")
clf.fit(X, y)
print("intercept:\n", clf.intercept_)
print("coefs:\n", clf.coef_)
print("params:\n", clf.get_params())

print("normalized version:")
clf1.fit(X, y)
print("intercept:\n", clf1.intercept_)
print("coefs:\n", clf1.coef_)
#+end_src

#+RESULTS:
#+BEGIN_SRC ipython
fit clf with X and y
intercept:
 152.938053729
coefs:
 [  -0.         -232.55152822  406.69613521  206.59905867   -0.
 -101.84408997 -200.24608227    0.          586.9163428    31.13599053]
params:
 {'copy_X': True, 'alpha': 0.2, 'positive': False, 'fit_intercept': True, 'selection': 'cyclic', 'random_state': None, 'tol': 0.0001, 'max_iter': 1000, 'precompute': False, 'warm_start': False, 'normalize': False}
normalized version:
intercept:
 153.03636832
coefs:
 [  -7.90708221 -293.9068369   421.64232226  252.50362756   -0.
 -160.86523098 -242.47747886    0.          607.65971782   54.52159238]
#+END_SRC

How cross validation with lasso is done:

#+begin_src ipython :session :exports both :results output code
this_scores = cross_validation.cross_val_score(clf, X, y, n_jobs=1)
this_scores1 = cross_validation.cross_val_score(clf, X, y, n_jobs=1)
this_scores_5fold = cross_validation.cross_val_score(clf, X, y, n_jobs=1, cv=5)
this_scores1_5fold = cross_validation.cross_val_score(clf, X, y, n_jobs=1, cv=5)
print(this_scores)
print(this_scores1)
print(this_scores_5fold)
print(this_scores1_5fold)
#+end_src

#+RESULTS:
#+BEGIN_SRC ipython
[ 0.51448194  0.19544042  0.40051502]
[ 0.51448194  0.19544042  0.40051502]
[ 0.42451284  0.39195894  0.37992449  0.35994941  0.5080667 ]
[ 0.42451284  0.39195894  0.37992449  0.35994941  0.5080667 ]
#+END_SRC



Here we eval a range of alphas from a log space from -4 to -0.5.
For each alpha, perform a 3-fold cv (default), rechieve their mean and std.
#+begin_src ipython :session :exports both :results output code
lasso = linear_model.Lasso()
alphas = np.logspace(-4, -.5, 30)

scores = list()
scores_std = list()

for alpha in alphas:
    lasso.alpha = alpha
    this_scores = cross_validation.cross_val_score(lasso, X, y, n_jobs=1)
    scores.append(np.mean(this_scores))
    scores_std.append(np.std(this_scores))

print("alpha scores, mean:\n", scores)
print("alpha scores, std:\n", scores_std)
#+end_src


#+RESULTS:
#+BEGIN_SRC ipython
alpha scores, mean:
 [0.34908310629208605, 0.34919799365334692, 0.34934947124816595, 0.34954907749739023, 0.34981210610663133, 0.35015826344685941, 0.35061336423021378, 0.35121121165860508, 0.35199461524868564, 0.35301935112217248, 0.35435492737811064, 0.35608875135777823, 0.35832605094532194, 0.36119022418421642, 0.36479554911103468, 0.36855937009834355, 0.37102097828257286, 0.37373637054940678, 0.37536354260979143, 0.3770153564733934, 0.37935475677572789, 0.38233055945292493, 0.38443899390608349, 0.38659469680193109, 0.38753399417933848, 0.38591915990727332, 0.38284243278745672, 0.37482125367269598, 0.35843307906864119, 0.33333268053469151]
alpha scores, std:
 [0.17451241085248051, 0.17448010554108545, 0.17443750121804383, 0.1743811969521345, 0.17430674868557761, 0.17420830220369743, 0.17407836965928783, 0.17390613688365741, 0.17367848234099145, 0.17337632491085306, 0.17297589404762292, 0.17244277638064354, 0.17173247100349204, 0.17078123395220091, 0.16949033405062597, 0.16846832800702879, 0.16992247044803077, 0.1713892573351983, 0.17153246543375339, 0.17130395109001145, 0.17057620239867216, 0.16916413955718559, 0.16609893538282133, 0.16221666985294944, 0.15727615263409947, 0.15191842456742446, 0.14319706225609974, 0.1346646141881537, 0.12712241105899977, 0.12229845382449046]
#+END_SRC

#+begin_src ipython :session :exports both :file image.png
plt.figure(figsize=(4, 3))
plt.semilogx(alphas, scores)
# plot error lines showing +/- std. errors of the scores
plt.semilogx(alphas, np.array(scores) + np.array(scores_std) / np.sqrt(len(X)),
             "b--")
plt.semilogx(alphas, np.array(scores) - np.array(scores_std) / np.sqrt(len(X)),
             "b--")
plt.ylabel("CV score")
plt.xlabel("alpha")
plt.axhline(np.max(scores), linestyle="--", color=".5")
plt.show()
#+end_src

#+RESULTS:
[[file:image.png]]

#+begin_src ipython :session :exports both :results output
##############################################################################
# Bonus: how much can you trust the selection of alpha?

# To answer this question we use the LassoCV object that sets its alpha
# parameter automatically from the data by internal cross-validation (i.e. it
# performs cross-validation on the training data it receives).
# We use external cross-validation to see how much the automatically obtained
# alphas differ across different cross-validation folds.
lasso_cv = linear_model.LassoCV(alphas=alphas)
k_fold = cross_validation.KFold(len(X), 3)

print("Answer to the bonus question:",
      "how much can you trust the selection of alpha?")
print()
print("Alpha parameters maximising the generalization score on different")
print("subsets of the data:")
for k, (train, test) in enumerate(k_fold):
    lasso_cv.fit(X[train], y[train])
    print("[fold {0}] alpha: {1:.5f}, score: {2:.5f}".
          format(k, lasso_cv.alpha_, lasso_cv.score(X[test], y[test])))
print()
print("Answer: Not very much since we obtained different alphas for different")
print("subsets of the data and moreover, the scores for these alphas differ")
print("quite substantially.")
#+end_src

#+RESULTS:
#+begin_example
Answer to the bonus question: how much can you trust the selection of alpha?

Alpha parameters maximising the generalization score on different
subsets of the data:
[fold 0] alpha: 0.10405, score: 0.53573
[fold 1] alpha: 0.05968, score: 0.16278
[fold 2] alpha: 0.10405, score: 0.44437

Answer: Not very much since we obtained different alphas for different
subsets of the data and moreover, the scores for these alphas differ
quite substantially.
#+end_example
